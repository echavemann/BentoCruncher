{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime\n",
    "import pandas_market_calendars as mcal\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def get_ticker_mapping():\n",
    "    \n",
    "    path = os.getcwd()\n",
    "    file_path = os.path.join(path, \"metadata.json\")\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        meta_data = json.load(f)\n",
    "\n",
    "    mappings = meta_data['symbology']['mappings']\n",
    "    tickers = mappings.keys()\n",
    "\n",
    "    new_mapping = {}\n",
    "    for ticker in tickers:\n",
    "        for dct in mappings[ticker]:\n",
    "            \n",
    "            date_range = pd.date_range(dct['d0'],dct['d1'])\n",
    "            date_str = [d.to_pydatetime().date().strftime(\"%Y-%m-%d\") for d in date_range]\n",
    "            date_str.pop(-1)\n",
    "            \n",
    "            s = dct['s']\n",
    "            \n",
    "            for date in date_str:\n",
    "                if not date in new_mapping: \n",
    "                    new_mapping[date] = {ticker:s}\n",
    "                else:\n",
    "                    new_mapping[date][ticker] = s\n",
    "    \n",
    "    return new_mapping, tickers\n",
    "                            \n",
    "            \n",
    "                    \n",
    "def get_date(file_name):\n",
    "    \"\"\"\n",
    "    takes in a file name, outputs the date in the file name as datetime obj\n",
    "    \"\"\"\n",
    "    \n",
    "    year, month, day = '','',''\n",
    "    counter = 0\n",
    "    i = 0\n",
    "    for i in range(len(file_name)):\n",
    "        if file_name[i].isdigit():\n",
    "            if counter < 4:\n",
    "                year += file_name[i]\n",
    "            elif counter < 6:\n",
    "                month += file_name[i]\n",
    "            elif counter < 8:\n",
    "                day += file_name[i]\n",
    "            counter += 1\n",
    "            \n",
    "    return datetime(int(year), int(month), int(day)).date().strftime(\"%Y-%m-%d\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing xnas-itch-20220103.ohlcv-1m.csv\n",
      "--- 0.32767796516418457 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def parse(data_folder_name = 'data', directory = None):\n",
    "    \"\"\"\n",
    "    put this file under a folder with supplied name (default to data)\n",
    "    it will parse the raw databento csv under same directory into readable formats\n",
    "    \"\"\"\n",
    "    if directory == None:\n",
    "        file_path = os.getcwd()\n",
    "    else:\n",
    "        file_path = directory\n",
    "        \n",
    "    files = os.listdir(file_path)\n",
    "    data_files =  []\n",
    "    \n",
    "    for file in files: \n",
    "        if file.endswith('ohlcv-1m.csv'):\n",
    "            data_files.append(file)\n",
    "\n",
    "    if data_files == []: raise ValueError('No file ending in ohlcv-1m.csv found in specified directory')\n",
    "    mapping, tickers = get_ticker_mapping()\n",
    "    \n",
    "    for file in sorted(data_files):\n",
    "            \n",
    "            print(f\"processing {file}\")\n",
    "            path = os.path.join(file_path,file)\n",
    "            df = pd.read_csv(path)\n",
    "            \n",
    "            d = get_date(file)\n",
    "                \n",
    "            cols = ['ts_event','open','high','low','close']\n",
    "            cleaned = pd.DataFrame()\n",
    "\n",
    "            for col in cols:\n",
    "                if df[col].dtypes != float and col != 'ts_event':\n",
    "                    df[col] = df[col].astype(float)\n",
    "                cleaned[col] = df[col]/1000000000\n",
    "                    \n",
    "            cleaned['ts_event'] = pd.to_datetime(df['ts_event'], unit='ns', origin='unix')\n",
    "            cleaned['volume'] = df['volume']\n",
    "            cleaned['product_id'] = df['product_id']\n",
    "            cleaned['ticker'] = cleaned['product_id']\n",
    "            d = cleaned.iloc[1]['ts_event'].strftime(\"%Y-%m-%d\")\n",
    "            d = mapping[d]\n",
    "            d = dict(zip(d.values(),d.keys()))\n",
    "            t = []\n",
    "            for i, row_value in cleaned['product_id'].items():\n",
    "                t.append(d[str(row_value)])\n",
    "            cleaned['ticker'] = t\n",
    "\n",
    "            date_str = get_date(file)\n",
    "\n",
    "            for ticker in tickers:\n",
    "                ticker_data = cleaned[cleaned['ticker'] == ticker]\n",
    "                if not ticker_data.empty:\n",
    "                    ticker_data_file_path = os.path.join(file_path, ticker)\n",
    "                    if not os.path.exists(ticker_data_file_path):\n",
    "                        os.makedirs(ticker_data_file_path)\n",
    "                    ticker_data.to_csv(os.path.join(ticker_data_file_path,f\"{ticker}-{date_str}.csv\"))\n",
    "\n",
    "            del df\n",
    "            del cleaned\n",
    "            del ticker_data\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "parse()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7cf1142b5ddd1e1daa93191adaf8330dff0916815175c263ce71424b6641312"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
